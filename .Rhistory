mtcars
mtcars2 <- ifelse(mtcars==0, 0, 1)
mtcars2
for j in tens {
tens <- 0:9
locs <- character()
for (i in tens) {
for (j in tens) {
for (k in tens) {
loc <- paste0("N 41 1",i,".",j,"96, W 072 55.",k,"16")
locs <- c(locs, loc)
}
}
}
head(locs)
df <- data.frame("locs"=locs)
View(df)
View(df)
write(locs, file="~/Dropbox/Creative/EscapeNewHaven_PuzzHunt/locs.txt")
View(df)
mtcars
names(mtcars)
rownames(mtcars)
grepl("Toyota", rownames(mtcars))
mtcars[grepl("Toyota", rownames(mtcars)),]
mtcars[!(grepl("Toyota", rownames(mtcars))),]
Though I could not find information as to the codes in the NOAA database handbook,
---
title: "Analysis of harm caused by severe weather events"
author: "Timothy Johnstone"
output:
html_document:
keep_md: yes
pdf_document: default
---
## Synopsis
*describes and summarizes the data analysis in less than 10 sentences*
## Data Processing
Before starting any analysis, we load all external libraries required for the code below. Note that this analysis requires the following libraries: *ggplot2*, *Hmisc*
```{r results='hide'}
require(ggplot2)
require(Hmisc)
```
Data were made available via the Coursera site as a bzipped csv file, and are originally provided by the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm database. Original documentation can be found [here](http://www.ncdc.noaa.gov/stormevents/pd01016005curr.pdf).
The first step is to read in the data from the bz2 file provided.
```{r}
# read.csv should handle bzip compressed files automatically, but we use bzfile just in case
weather <- read.csv(bzfile('repdata_data_StormData.csv.bz2'), header=T, na.strings = "")
```
Before working with the dataset, let's make sure it loaded in properly by checking the first few columns:
```{r}
summary(weather[,1:10])
```
Since the weather events are organized by when they occurred, we'll check the distribution over the years to get an idea of the density over time.
```{r}
# Properly format dates as posix dates and plot begin dates on a histogram
weather$BGN_DATE <- as.Date(weather$BGN_DATE, format = "%m/%d/%Y %H:%M:%S")
hist(weather$BGN_DATE,
col="steelblue",
xlab="Year", breaks=40,
main="Distribution of severe weather observations over time")
weather$END_DATE <- format(as.Date(weather$END_DATE, format = "%m/%d/%Y %H:%M:%S"), "%m/%d/%Y")
```
By eye, it seems like the observations start increasing around 1990. Since there's likely to be missing and/or lower quality data before this point, let's just check that we won't be eliminating too much of the dataset by subsetting to dates after 1990. We do this by looking at the decile cutoffs for our date set.
```{r}
as.Date(quantile(as.numeric(weather$BGN_DATE), seq(0.1, 1, by=0.1)), origin="1970-01-01")
```
It looks like we'll be eliminating less than 20% of the observations in order to ensure higher quality/frequency of observations. This will also make the dataset easier to work with, so let's do it!
```{r}
cutoff1990 <- as.numeric(as.Date("01/01/1990", format = "%m/%d/%Y"))
weather <- weather[as.numeric(weather$BGN_DATE) >= cutoff1990,]
# I would plot another histogram to see that the distribution is more balanced, but we are limited to 3 plots in our output...........
#hist(weather$BGN_DATE,
#     col="steelblue",
#     xlab="Year", breaks=20,
#     main="Distribution of severe weather observations over time, after date filtering")
```
This looks like a more balanced distribution.
Now we can also subset the table to just the columns that we will be using for the weather consequences analysis. This will shrink the table and make the data easier to work with. Preserved columns are the following:
| Variable Name | Description                                            |
|---------------|--------------------------------------------------------|
| BGN_DATE      | The date (mm-dd-yyyy) of the severe weather event      |
| EVTYPE        | The type of weather event e.g. thunderstorm            |
| FATALITIES    | Number of fatalities resulting from the weather event  |
| INJURIES      | Number of injuries resulting from the weather event    |
| PROPDMG       | Property damage, in USD                                |
| PROPDMGEXP    | Multiplier for property damage, according to NOAA code |
| CROPDMG       | Agricultural crop damage, in USD                       |
| CROPDMGEXP    | Multiplier for crop damage, according to NOAA code     |
```{r}
weather <- weather[, c("EVTYPE","FATALITIES","INJURIES", "PROPDMG", "PROPDMGEXP", "CROPDMG", "CROPDMGEXP")]
```
Next, we have to process a few columns which use specific encoding of exponents in order to recover the original numeric values. Looking at the original codebook, there are two columns, *PROPDMGEXP* and *CROPDMGEXP*, that represent the size units of the *PROPDMG* and *CROPDMG* columns respectively.
```{r}
levels(weather$PROPDMGEXP)
levels(weather$CROPDMGEXP)
```
Though I could not find information as to the codes in the NOAA database handbook,
## Results
### Effects of severe weather events on population health
Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?
### Economic consequences of severe weather events
Across the United States, which types of events have the greatest economic consequences?
## Conclusions
*At most 3 figures*
require(ggplot2)
require(Hmisc)
# read.csv should handle bzip compressed files automatically, but we use bzfile just in case
weather <- read.csv(bzfile('repdata_data_StormData.csv.bz2'), header=T, na.strings = "")
setwd("~/Dropbox/Coursera/5_Reproducible_Research/Projects/RR_Proj2_HarmfulWeatherEvents")
weather <- read.csv(bzfile('repdata_data_StormData.csv.bz2'), header=T, na.strings = "")
weather$BGN_DATE <- as.Date(weather$BGN_DATE, format = "%m/%d/%Y %H:%M:%S")
hist(weather$BGN_DATE,
col="steelblue",
xlab="Year", breaks=40,
main="Distribution of severe weather observations over time")
weather$END_DATE <- format(as.Date(weather$END_DATE, format = "%m/%d/%Y %H:%M:%S"), "%m/%d/%Y")
as.Date(quantile(as.numeric(weather$BGN_DATE), seq(0.1, 1, by=0.1)), origin="1970-01-01")
cutoff1990 <- as.numeric(as.Date("01/01/1990", format = "%m/%d/%Y"))
weather <- weather[as.numeric(weather$BGN_DATE) >= cutoff1990,]
# I would plot another histogram to see that the distribution is more balanced, but we are limited to 3 plots in our output...........
#hist(weather$BGN_DATE,
#     col="steelblue",
#     xlab="Year", breaks=20,
#     main="Distribution of severe weather observations over time, after date filtering")
levels(weather$PROPDMGEXP)
levels(weather$CROPDMGEXP)
10e2
10e0
union(levels(weather$PROPDMGEXP), levels(weather$CROPDMGEXP))
1e0
1e2
match("k",translateExp$exp)
translateExp <- data.frame("exp"=exps,
"num"=c(NA, NA, NA,
1e0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8,
1e9, 1e2, 1e2, 1e3, 1e6, 1e6, 1e3))
exps <- union(levels(weather$PROPDMGEXP), levels(weather$CROPDMGEXP))
translateExp <- data.frame("exp"=exps,
"num"=c(NA, NA, NA,
1e0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8,
1e9, 1e2, 1e2, 1e3, 1e6, 1e6, 1e3))
match("k",translateExp$exp)
translateExp$num[match("k",translateExp$exp)]
weather$CROPDMG <- weather$CROPDMG * translateExp$num[match(weather$CROPDMGEXP,translateExp$exp)]
head(weather$CROPDMG)
tail(weather$CROPDMG)
tail(weather$CROPDMG, 500)
tail(weather$CROPDMG, 5000)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
weather$PROPDMGabs <- weather$PROPDMG * translateExp$num[match(weather$PROPDMGEXP,translateExp$exp)]
translateExp <- data.frame("exp"=exps,
"num"=c(1e0, NA, NA, NA,
1e0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8,
1e9, 1e2, 1e2, 1e3, 1e6, 1e6, 1e3))
weather$CROPDMGabs <- weather$CROPDMG * translateExp$num[match(weather$CROPDMGEXP,translateExp$exp)]
weather$PROPDMGabs <- weather$PROPDMG * translateExp$num[match(weather$PROPDMGEXP,translateExp$exp)]
install.packages('xtable')
require(xtable)
injByType_total <- aggregate(weather$INJURIES, by=weather$EVTYPE, sum, na.rm=T)
injByType_mean <- aggregate(weather$INJURIES, by=weather$EVTYPE, mean, na.rm=T)
injByType_total <- aggregate(INJURIES ~ EVTYPE, data=weather, sum, na.rm=T)
injByType_mean <- aggregate(INJURIES ~ EVTYPE, data=weather, mean, na.rm=T)
plot(injByType_mean)
?xtable
```{r results="asis"}
# Print the top 10 most injuring weather types, by total injuries
table_injByType_total <- xtable(injByType_total[1:20,])
print(table_injByType_total, type='html')
tail(injByType_mean)
tail(injByType_total)
injByType_total <- aggregate(INJURIES ~ EVTYPE, data=weather, sum, na.rm=T)
injByType_total <- injByType_total[order(-injByType_total$INJURIES)]
injByType_mean <- aggregate(INJURIES ~ EVTYPE, data=weather, mean, na.rm=T)
injByType_mean <- injByType_mean[order(-injByType_mean$INJURIES)]
injByType_total <- injByType_total[order(-injByType_total$INJURIES),]
injByType_mean <- injByType_mean[order(-injByType_mean$INJURIES),]
tail(injByType_total)
table_injByType_total <- xtable(injByType_total[1:20,])
print(table_injByType_total, type='html')
# Print the top 10 most injuring weather types, by mean injuries
print(xtable(injByType_mean[1:20,]), type='html')
fatByType_total <- aggregate(FATALITIES ~ EVTYPE, data=weather, sum, na.rm=T)
fatByType_total <- fatByType_total[order(-fatByType_total$FATALITIES),]
fatByType_mean <- aggregate(FATALITIES ~ EVTYPE, data=weather, mean, na.rm=T)
fatByType_mean <- fatByType_mean[order(-fatByType_mean$FATALITIES),]
tail(fatByType_total)
injuriousTypoes
injuriousTypes
fatalTypes <- sum(fatByType_total$FATALITIES>0)/nrow(fatByType_total)*100
fatalTypes
print(xtable(fatByType_total[1:10,]), type='html')
print(xtable(fatByType_mean[1:10,]), type='html')
allByType_total <- merge(injByType_total, fatByType_total, by="EVTYPE")
allByType_total$TOTAL <- allByType_total$INJURIES + allByType_total$FATALITIES
allByType_total <- allByType_total[order(-allByType_total$TOTAL),]
allByType_mean <- merge(injByType_mean, fatByType_mean, by="EVTYPE")
allByType_mean$TOTAL <- allByType_mean$INJURIES + allByType_mean$FATALITIES
allByType_mean <- allByType_mean[order(-allByType_mean$TOTAL),]
print(xtable(allByType_total[1:10,1:4]), type='html')
print(xtable(allByType_mean[1:10,1:4]), type='html')
table(head(allByType_total))
table(head(allByType_total$FATALITIES), head(allByType_total$INJURIES))
barplot(table(head(allByType_total$FATALITIES), head(allByType_total$INJURIES)))
head(mtcars)
table(mtcars$vs, mtcars$gear)
propByType_total <- aggregate(PROPDMGabs ~ EVTYPE, data=weather, sum, na.rm=T)
propByType_total <- propByType_total[order(-propByType_total$PROPDMGabs),]
propByType_mean <- aggregate(PROPDMGabs ~ EVTYPE, data=weather, mean, na.rm=T)
propByType_mean <- propByType_mean[order(-propByType_mean$PROPDMGabs),]
tail(propByType_total)
propTypes <- sum(propByType_total$PROPDMGabs>0)/nrow(propByType_total)*100
print(xtable(propByType_total[1:10,1:2]), type='html')
print(xtable(propByType_mean[1:10,1:2]), type='html')
cropByType_total <- aggregate(CROPDMGabs ~ EVTYPE, data=weather, sum, na.rm=T)
cropByType_total <- cropByType_total[order(-cropByType_total$CROPDMGabs),]
cropByType_mean <- aggregate(CROPDMGabs ~ EVTYPE, data=weather, mean, na.rm=T)
cropByType_mean <- cropByType_mean[order(-cropByType_mean$CROPDMGabs),]
tail(cropByType_total)
cropTypes <- sum(cropByType_total$CROPDMGabs>0)/nrow(cropByType_total)*100
print(xtable(cropByType_total[1:10,1:2]), type='html')
print(xtable(cropByType_mean[1:10,1:2]), type='html')
dmgByType_total <- merge(cropByType_total, propByType_total, by="EVTYPE")
dmgByType_total$TOTAL <- dmgByType_total$CROPDMGabs + dmgByType_total$PROPDMGabs
dmgByType_total <- dmgByType_total[order(-dmgByType_total$TOTAL),]
dmgByType_mean <- merge(cropByType_mean, propByType_mean, by="EVTYPE")
dmgByType_mean$TOTAL <- dmgByType_mean$CROPDMGabs + dmgByType_mean$PROPDMGabs
dmgByType_mean <- dmgByType_mean[order(-dmgByType_mean$TOTAL),]
print(xtable(dmgByType_total[1:10,1:4]), type='html')
print(xtable(dmgByType_mean[1:10,1:4]), type='html')
